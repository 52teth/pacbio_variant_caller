"""
Rules to align PacBio reads to a given reference assembly and summarize
alignments.
"""

# Create a list of BAM files for downstream analysis.
rule align_reads:
    input: dynamic("alignments/{batch_id}.bam")
    output: "alignments.fofn"
    params: sge_opts=""
    shell: "for alignment in {input}; do echo `pwd`/$alignment; done > {output}"

# Collect summary of aligned read lengths.
rule collect_alignment_summaries:
    input: dynamic("alignment_lengths/{batch_id}.tab")
    output: "alignment_lengths.tab"
    params: sge_opts=""
    shell: "cat {input} > {output}"

# Summarize alignments by length.
# TODO: get subread lengths at the same time as the aligned lengths.
rule get_alignment_lengths:
    input: "alignments/{batch_id}.bam"
    output: "alignment_lengths/{batch_id}.tab"
    params: sge_opts=""
    shell: """samtools view {input} | awk 'OFS="\\t" {{ if ($3 == "*") {{ print "unmapped",length($10) }} else {{ print "mapped",$9 }} }}' > {output}"""

# Collect summary of subread lengths prior to alignment.
rule collect_subread_summaries:
    input: dynamic("subread_lengths/{batch_id}.txt")
    output: "subread_lengths.tab"
    params: sge_opts=""
    shell: """awk 'OFS="\\t" {{ print "subread",$1 }}' {input} > {output}"""

# Summarize length of subreads using coordinates in the mapped and unmapped
# subread names.
rule get_subread_lengths:
    input: "alignments/{batch_id}.bam"
    output: "subread_lengths/{batch_id}.txt"
    params: sge_opts=""
    shell:
        "mkdir -p {TMP_DIR}; "
        """samtools view {input} | awk '{{ num_of_pieces=split($1, pieces, "/"); num_of_coords=split(pieces[3], coords, "_"); print coords[2] - coords[1] }}' > {TMP_DIR}/subreads.{wildcards.batch_id}.txt; """
        "rsync --remove-source-files {TMP_DIR}/subreads.{wildcards.batch_id}.txt {output}"

# Sync input reads and reference assembly to local disk, align reads, sort
# output, and write final BAM to shared disk.
rule align_batch:
    input: reads="batched_reads/{batch_id}.fofn", reference=config["reference"]["assembly"], suffix=config["reference"]["suffix_array"], ctab=config["reference"]["ctab"]
    output: "alignments/{batch_id}.bam"
    params: sge_opts="-l disk_free=70G -l mfree=3G -pe serial 12 -N align_batch_{batch_id}", threads="8", samtools_threads="4", samtools_memory="4G", bwlimit="20000"
    shell:
        "mkdir -p {TMP_DIR}/{wildcards.batch_id};"
        "cd {TMP_DIR}/{wildcards.batch_id};"
        "rsync --bwlimit={params.bwlimit} -LW --no-relative --files-from={CWD}/{input.reads} / .;"
        """find ./ -name "*.bax.h5" > input.fofn;"""
        "{BLASR_BIN} input.fofn {input.reference} -unaligned /dev/null -out /dev/stdout -sam -sa {input.suffix} -ctab {input.ctab} -nproc {params.threads} -bestn 2 -maxAnchorsPerPosition 100 -advanceExactMatches 10 -affineAlign -affineOpen 100 -affineExtend 0 -insertion 5 -deletion 5 -extend -maxExtendDropoff 50 -clipping subread | samtools sort -@ {params.samtools_threads} -m {params.samtools_memory} -O bam -T {wildcards.batch_id} -o {wildcards.batch_id}.bam -;"
        "samtools index {wildcards.batch_id}.bam;"
        "rsync --bwlimit={params.bwlimit} --remove-source-files -W {wildcards.batch_id}.bam* {CWD}/`dirname {output}`/;"
        "rm -rf {TMP_DIR}/{wildcards.batch_id}"

# Divide input reads into batches for alignment.
rule assign_batches:
    input: config["reads"]
    output: dynamic("batched_reads/{batch_id}.fofn")
    params: sge_opts=""
    run:
        output_dir = os.path.dirname(output[0])
        shell("rm -rf %s; mkdir -p %s" % (output_dir, output_dir))

        with open(input[0], "r") as fh:
            input_files = [os.path.realpath(line.rstrip()) for line in fh]

        sizes_by_file = dict([(fofn, os.path.getsize(fofn))
                              for fofn in input_files if os.path.exists(fofn)])

        # Assign batches based on the total size of the files per batch. This
        # should produce roughly equally-sized output files.
        size_per_batch = float(config["alignment"]["size_per_batch"])
        total_file_sizes = 0

        for fofn, fofn_size in sizes_by_file.items():
            batch_id = math.floor(total_file_sizes / size_per_batch)
            current_output = open("%s/%s.fofn" % (output_dir, batch_id), "a")
            current_output.write("%s\n" % fofn)
            current_output.close()
            total_file_sizes += fofn_size
