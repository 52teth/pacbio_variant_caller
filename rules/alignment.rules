"""
Rules to align PacBio reads to a given reference assembly and summarize
alignments.
"""
localrules: assign_batches

# Create a list of BAM files for downstream analysis.
rule align_reads:
    input: dynamic("alignments/{batch_id}.bam")
    output: "alignments.fofn"
    params: sge_opts=""
    shell: "for alignment in {input}; do echo `pwd`/$alignment; done > {output}"

# Plot alignment lengths.
rule plot_alignment_summaries:
    input: "alignment_lengths.tab"
    output: "alignment_lengths.pdf"
    params: sge_opts=""
    shell: "Rscript plot_read_lengths_by_type.R {input} {output}"

# Collect summary of aligned read lengths.
rule collect_alignment_summaries:
    input: dynamic("alignment_lengths/{batch_id}.tab")
    output: "alignment_lengths.tab"
    params: sge_opts=""
    shell: """awk 'OFS="\\t" {{ if (NR == 1) {{ print "alignment_status","subread_length","aligned_length" }} print }}' {input} > {output}"""

# Summarize alignments by length.
# TODO: get subread lengths at the same time as the aligned lengths.
rule get_subread_and_alignment_lengths:
    input: "alignments/{batch_id}.bam"
    output: "alignment_lengths/{batch_id}.tab"
    params: sge_opts="", mapping_quality_threshold="30"
    shell:
        "mkdir -p {TMP_DIR}; "
        """samtools view {input} | awk 'OFS="\\t" {{ if ($3 == "*" || $5 >= {params.mapping_quality_threshold}) {{ num_of_pieces = split($1, pieces, "/"); num_of_coords = split(pieces[3], coords, "_"); subread_length = coords[2] - coords[1]; if ($3 == "*") {{ print "unmapped",subread_length,length($10) }} else if ($5 >= 30) {{ print "mapped",subread_length,$9 }} }} }}' > {TMP_DIR}/lengths.`basename {output}`; """
        "rsync --remove-source-files {TMP_DIR}/lengths.`basename {output}` {output}; "

# Sync input reads and reference assembly to local disk, align reads, sort
# output, and write final BAM to shared disk.
rule align_batch:
    input: reads="batched_reads/{batch_id}.fofn", reference=config["reference"]["assembly"], suffix=config["reference"]["suffix_array"], ctab=config["reference"]["ctab"]
    output: "alignments/{batch_id}.bam"
    params: sge_opts="-l disk_free=70G -l mfree=3.25G -pe serial 12 -N align_batch_{batch_id}", threads="10", samtools_threads="2", samtools_memory="4G", bwlimit="20000"
    shell:
        "mkdir -p {TMP_DIR}/{wildcards.batch_id}; "
        "cd {TMP_DIR}/{wildcards.batch_id}; "
        "rsync --bwlimit={params.bwlimit} -LW --no-relative --files-from={CWD}/{input.reads} / .; "
        """find ./ -name "*.bax.h5" > input.fofn; """
        "{BLASR_BIN} input.fofn {input.reference} -unaligned /dev/null -out /dev/stdout -sam -sa {input.suffix} -ctab {input.ctab} -nproc {params.threads} -bestn 2 -maxAnchorsPerPosition 100 -advanceExactMatches 10 -affineAlign -affineOpen 100 -affineExtend 0 -insertion 5 -deletion 5 -extend -maxExtendDropoff 50 -clipping subread | samtools sort -@ {params.samtools_threads} -m {params.samtools_memory} -O bam -T {wildcards.batch_id} -o {wildcards.batch_id}.bam -; "
        "samtools index {wildcards.batch_id}.bam; "
        "rsync --bwlimit={params.bwlimit} --remove-source-files -W {wildcards.batch_id}.bam* {CWD}/`dirname {output}`/; "
        "rm -rf {TMP_DIR}/{wildcards.batch_id}"

# Divide input reads into batches for alignment.
rule assign_batches:
    input: config["reads"]
    output: dynamic("batched_reads/{batch_id}.fofn")
    params: sge_opts=""
    run:
        output_dir = os.path.dirname(output[0])
        shell("rm -rf %s; mkdir -p %s" % (output_dir, output_dir))

        with open(input[0], "r") as fh:
            input_files = [os.path.realpath(line.rstrip()) for line in fh]

        sizes_by_file = [(fofn, os.path.getsize(fofn))
                         for fofn in input_files if os.path.exists(fofn)]

        # Assign batches based on the total size of the files per batch. This
        # should produce roughly equally-sized output files.
        size_per_batch = float(config["alignment"]["size_per_batch"])
        total_file_sizes = 0

        for fofn, fofn_size in sizes_by_file:
            batch_id = math.floor(total_file_sizes / size_per_batch)
            current_output = open("%s/%s.fofn" % (output_dir, batch_id), "a")
            current_output.write("%s\n" % fofn)
            current_output.close()
            total_file_sizes += fofn_size
